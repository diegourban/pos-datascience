{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling e Standardization\n",
    "\n",
    "Uma boa referência https://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "\n",
    "A normalização de _features_ é necessária para evitar que um algoritmo seja enviesado pela magnitude de uma determinada _feature_.\n",
    "\n",
    "Por exemplo, se desejamos prever o preço de um carro (R$) baseado na idade do carro (anos) e na quilometragem (km), podemos ter um problema se as _features_ (idade e quilometragem) não forem normalizadas.\n",
    "\n",
    "O problema é que uma variação $\\delta = 1$ tem um impacto diferente para a idade do carro (medida em anos) e quilometragem (normalmente medida em milhares de quilometros).\n",
    "\n",
    "Para evitar esse problema, é possível transformar as _features_ de duas formas:\n",
    "\n",
    "## Feature Standardization\n",
    "\n",
    "Centraliza a média dos dados em 0 e desvio padrão em 1.\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "## Feature Scaling (Min-Max norm)\n",
    "\n",
    "Valor mínimo dos dados será 0 e valor máximo será 1.\n",
    "\n",
    "$$\n",
    "X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 12  9 10 11  1 10  1  4  8]\n",
      "----------\n",
      "[  467 10101  9940  6523  5100  1050  5214   922  3190  1053]\n",
      "----------\n",
      "[[    0    12     9    10    11     1    10     1     4     8]\n",
      " [  467 10101  9940  6523  5100  1050  5214   922  3190  1053]]\n",
      "----------\n",
      "[[0.0000e+00 4.6700e+02]\n",
      " [1.2000e+01 1.0101e+04]\n",
      " [9.0000e+00 9.9400e+03]\n",
      " [1.0000e+01 6.5230e+03]\n",
      " [1.1000e+01 5.1000e+03]\n",
      " [1.0000e+00 1.0500e+03]\n",
      " [1.0000e+01 5.2140e+03]\n",
      " [1.0000e+00 9.2200e+02]\n",
      " [4.0000e+00 3.1900e+03]\n",
      " [8.0000e+00 1.0530e+03]]\n"
     ]
    }
   ],
   "source": [
    "# criamos uma base de exemplo\n",
    "N = 10\n",
    "\n",
    "anos = np.random.randint(0, 15, size=N)\n",
    "quilometragem = (anos + 1) * np.random.randint(100, 1000, size=N)\n",
    "print(anos)\n",
    "print('----------')\n",
    "print(quilometragem)\n",
    "print('----------')\n",
    "\n",
    "# a primeira linha é o ano do carro e a segunda tem a quilometragem\n",
    "dados = np.vstack([anos, quilometragem])\n",
    "print(dados)\n",
    "print('----------')\n",
    "\n",
    "# transposta da matriz para ter uma amostra (ano, quilometragem) por linha\n",
    "dados = np.float32(dados.T)\n",
    "print(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia(p1, p2):\n",
    "    diff_quadrado = np.square(p1 - p2) \n",
    "    return np.sqrt(diff_quadrado.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 9.63401e+03, 9.47300e+03, 6.05601e+03, 4.63301e+03,\n",
       "        5.83000e+02, 4.74701e+03, 4.55000e+02, 2.72300e+03, 5.86050e+02],\n",
       "       [9.63401e+03, 0.00000e+00, 1.61030e+02, 3.57800e+03, 5.00100e+03,\n",
       "        9.05101e+03, 4.88700e+03, 9.17901e+03, 6.91100e+03, 9.04800e+03],\n",
       "       [9.47300e+03, 1.61030e+02, 0.00000e+00, 3.41700e+03, 4.84000e+03,\n",
       "        8.89000e+03, 4.72600e+03, 9.01800e+03, 6.75000e+03, 8.88700e+03],\n",
       "       [6.05601e+03, 3.57800e+03, 3.41700e+03, 0.00000e+00, 1.42300e+03,\n",
       "        5.47301e+03, 1.30900e+03, 5.60101e+03, 3.33301e+03, 5.47000e+03],\n",
       "       [4.63301e+03, 5.00100e+03, 4.84000e+03, 1.42300e+03, 0.00000e+00,\n",
       "        4.05001e+03, 1.14000e+02, 4.17801e+03, 1.91001e+03, 4.04700e+03],\n",
       "       [5.83000e+02, 9.05101e+03, 8.89000e+03, 5.47301e+03, 4.05001e+03,\n",
       "        0.00000e+00, 4.16401e+03, 1.28000e+02, 2.14000e+03, 7.62000e+00],\n",
       "       [4.74701e+03, 4.88700e+03, 4.72600e+03, 1.30900e+03, 1.14000e+02,\n",
       "        4.16401e+03, 0.00000e+00, 4.29201e+03, 2.02401e+03, 4.16100e+03],\n",
       "       [4.55000e+02, 9.17901e+03, 9.01800e+03, 5.60101e+03, 4.17801e+03,\n",
       "        1.28000e+02, 4.29201e+03, 0.00000e+00, 2.26800e+03, 1.31190e+02],\n",
       "       [2.72300e+03, 6.91100e+03, 6.75000e+03, 3.33301e+03, 1.91001e+03,\n",
       "        2.14000e+03, 2.02401e+03, 2.26800e+03, 0.00000e+00, 2.13700e+03],\n",
       "       [5.86050e+02, 9.04800e+03, 8.88700e+03, 5.47000e+03, 4.04700e+03,\n",
       "        7.62000e+00, 4.16100e+03, 1.31190e+02, 2.13700e+03, 0.00000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distancias = np.zeros(shape=(N, N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        distancias[i, j] = distancia(dados[i, :], dados[j, :])\n",
    "distancias.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature standardization\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.8743018e-08 0.0000000e+00]\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "media = dados.mean(axis=0) # calcula a média para cada coluna\n",
    "# media = np.mean(dados, axis=0)\n",
    "desvio_padrao = dados.std(axis=0) # calcula o desvio padrão para cada coluna\n",
    "# desvio_padrao = np.std(dados, axis=0)\n",
    "\n",
    "X = dados\n",
    "Z = (X - media) / desvio_padrao\n",
    "\n",
    "print(Z.mean(axis=0))\n",
    "print(Z.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 3.9 , 3.42, 2.87, 2.84, 0.28, 2.66, 0.26, 1.2 , 1.83],\n",
       "       [3.9 , 0.  , 0.69, 1.13, 1.46, 3.62, 1.48, 3.65, 2.7 , 2.76],\n",
       "       [3.42, 0.69, 0.  , 1.01, 1.47, 3.15, 1.38, 3.18, 2.26, 2.57],\n",
       "       [2.87, 1.13, 1.01, 0.  , 0.47, 2.59, 0.38, 2.61, 1.67, 1.64],\n",
       "       [2.84, 1.46, 1.47, 0.47, 0.  , 2.56, 0.23, 2.58, 1.69, 1.35],\n",
       "       [0.28, 3.62, 3.15, 2.59, 2.56, 0.  , 2.38, 0.04, 0.92, 1.6 ],\n",
       "       [2.66, 1.48, 1.38, 0.38, 0.23, 2.38, 0.  , 2.4 , 1.49, 1.28],\n",
       "       [0.26, 3.65, 3.18, 2.61, 2.58, 0.04, 2.4 , 0.  , 0.95, 1.6 ],\n",
       "       [1.2 , 2.7 , 2.26, 1.67, 1.69, 0.92, 1.49, 0.95, 0.  , 1.1 ],\n",
       "       [1.83, 2.76, 2.57, 1.64, 1.35, 1.6 , 1.28, 1.6 , 1.1 , 0.  ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distancias = np.zeros(shape=(N, N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        distancias[i, j] = distancia(Z[i, :], Z[j, :])\n",
    "distancias.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X_max = dados.max(axis=0) # valor máximo por coluna\n",
    "X_min = dados.min(axis=0) # valor mínimo por coluna\n",
    "\n",
    "X = dados\n",
    "X_norm = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "print(X_norm.max(axis=0))\n",
    "print(X_norm.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 1.  , 0.98, 0.63, 0.48, 0.06, 0.49, 0.05, 0.28, 0.06],\n",
       "       [1.  , 0.  , 0.02, 0.37, 0.52, 0.94, 0.51, 0.95, 0.72, 0.94],\n",
       "       [0.98, 0.02, 0.  , 0.35, 0.5 , 0.92, 0.49, 0.94, 0.7 , 0.92],\n",
       "       [0.63, 0.37, 0.35, 0.  , 0.15, 0.57, 0.14, 0.58, 0.35, 0.57],\n",
       "       [0.48, 0.52, 0.5 , 0.15, 0.  , 0.42, 0.01, 0.43, 0.2 , 0.42],\n",
       "       [0.06, 0.94, 0.92, 0.57, 0.42, 0.  , 0.43, 0.01, 0.22, 0.  ],\n",
       "       [0.49, 0.51, 0.49, 0.14, 0.01, 0.43, 0.  , 0.45, 0.21, 0.43],\n",
       "       [0.05, 0.95, 0.94, 0.58, 0.43, 0.01, 0.45, 0.  , 0.24, 0.01],\n",
       "       [0.28, 0.72, 0.7 , 0.35, 0.2 , 0.22, 0.21, 0.24, 0.  , 0.22],\n",
       "       [0.06, 0.94, 0.92, 0.57, 0.42, 0.  , 0.43, 0.01, 0.22, 0.  ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distancias = np.zeros(shape=(N, N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        distancias[i, j] = distancia(X_norm[i, :], X_norm[j, :])\n",
    "distancias.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note como as distâncias são menores. O principal motivo é que agora a `quilometragem` e `anos` estão na mesma escala, portanto, nenhuma das duas variáveis desequilibra a distrância devido a sua magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéricos\n",
    "\n",
    "Preços: R$ 1.432,78 e US$ 2,143.76 (note a diferença do separador decimal/milhar)\n",
    "\n",
    "Temperatura: 32ºC, 40ºF (escalas diferentes)\n",
    "\n",
    "Hora: 2PM, 14:00, 14.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432.78\n",
      "1432.78\n"
     ]
    }
   ],
   "source": [
    "preco = 'R$ 1.432,78'\n",
    "preco = preco.replace('.', '').replace(',', '.')\n",
    "m = re.search(r'\\d[\\d.]+', preco)\n",
    "preco = float(m[0])\n",
    "print(preco)\n",
    "\n",
    "preco = 'US$ 1,432.78'\n",
    "preco = preco.replace(',', '')\n",
    "m = re.search(r'\\d[\\d.]+', preco)\n",
    "preco = float(m[0])\n",
    "print(preco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
