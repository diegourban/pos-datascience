{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "Trabalho Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94471057"
      },
      "source": [
        "### Classificação de textos para análise de sentimentos\n",
        "\n",
        "Base de dados \n",
        "\n",
        "Instruções:\n",
        "- O objetivo deste trabalho é criar um modelo binário de aprendizado de máquina para classificação de textos. \n",
        "Para isso, será utilizado a base de dados [IMDb](http://ai.stanford.edu/~amaas/data/sentiment/), que consiste de dados textuais de críticas positivas e negativas de filmes\n",
        "- Uma vez treinado, o modelo deve ter uma função `predict` que recebe uma string como parâmetro e retorna o valor 1 ou 0, aonde 1 significa uma crítica positiva e 0 uma crítica negativa\n",
        "- O pré-processamento pode ser desenvolvidado conforme desejar (ex.: remoção de stopwords, word embedding, one-hot encoding, char encoding)\n",
        "- É preferível que seja empregado um modelo de recorrência (ex.: rnn, lstm, gru) para a etapa de classificação\n",
        "- Documente o código (explique sucintamente o que cada função faz, insira comentários em trechos de código relevantes)\n",
        "- **Atenção**: Uma vez treinado o modelo final, salve-o no diretório do seu projeto e crie uma célula ao final do notebook contendo uma função de leitura deste arquivo, juntamente com a execução da função `predict`\n",
        "\n",
        "Sugestões:\n",
        "- Explorar a base de dados nas células iniciais do notebook para ter um melhor entendimento do problema, distribuição dos dados, etc\n",
        "- Após desenvolver a estrutura de classificação, é indicado fazer uma busca de hiperparâmetros e comparar os resultados obtidos em diferentes situações\n",
        "\n",
        "Prazo de entrega:\n",
        "- 01-08-2021 às 23:59hs GMT-3\n",
        "\n",
        "Formato preferível de entrega:\n",
        "- Postar no portal Ava da disciplina o link do projeto no github (ou anexar o projeto diretamente no portal Ava)\n",
        "\n",
        "luann.porfirio@gmail.com"
      ],
      "id": "94471057"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-10T00:36:57.559764Z",
          "start_time": "2021-06-10T00:36:52.638020Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2577de36",
        "outputId": "46100ab0-580d-4459-ef7b-8c7072a3180c"
      },
      "source": [
        "!pip install torchtext"
      ],
      "id": "2577de36",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-10T00:44:12.514627Z",
          "start_time": "2021-06-10T00:44:12.509125Z"
        },
        "id": "a80224ad"
      },
      "source": [
        "import nltk\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from torchtext import datasets\n",
        "from torch import nn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model"
      ],
      "id": "a80224ad",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-10T00:50:27.424355Z",
          "start_time": "2021-06-10T00:49:16.448387Z"
        },
        "id": "907e3626"
      },
      "source": [
        "train_iter, test_iter = datasets.IMDB()"
      ],
      "id": "907e3626",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh3CnDI1xP9C"
      },
      "source": [
        "dataset_imdb = list(train_iter + test_iter)"
      ],
      "id": "Sh3CnDI1xP9C",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM9X6ouJwUaQ"
      },
      "source": [
        "df_imdb_raw = pd.DataFrame(data=dataset_imdb, columns=['sentiment', 'review'])"
      ],
      "id": "DM9X6ouJwUaQ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cl7GE5hxfIX",
        "outputId": "10693794-1bfe-421e-c0aa-5227fbb74071"
      },
      "source": [
        "df_imdb_raw.shape"
      ],
      "id": "9Cl7GE5hxfIX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSQdTH1ow84Y",
        "outputId": "7da38b9f-d4e4-4c61-c16b-d6ab2c7e0e47"
      },
      "source": [
        "df_imdb_raw.head()"
      ],
      "id": "DSQdTH1ow84Y",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>If only to avoid making this type of film in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>This film was probably inspired by Godard's Ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                             review\n",
              "0       neg  I rented I AM CURIOUS-YELLOW from my video sto...\n",
              "1       neg  \"I Am Curious: Yellow\" is a risible and preten...\n",
              "2       neg  If only to avoid making this type of film in t...\n",
              "3       neg  This film was probably inspired by Godard's Ma...\n",
              "4       neg  Oh, brother...after hearing about this ridicul..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx1GrlDayFYN",
        "outputId": "88c55764-b27d-4d68-c6fb-15f482b7ae71"
      },
      "source": [
        "df_imdb_raw.info()"
      ],
      "id": "Tx1GrlDayFYN",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   sentiment  50000 non-null  object\n",
            " 1   review     50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "31q5vFWqx9yi",
        "outputId": "5df05291-f1de-4cd7-d056-a3109281a8f7"
      },
      "source": [
        "df_imdb_raw.describe()"
      ],
      "id": "31q5vFWqx9yi",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000</td>\n",
              "      <td>50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>49582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>neg</td>\n",
              "      <td>Loved today's show!!! It was a variety and not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>25000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentiment                                             review\n",
              "count      50000                                              50000\n",
              "unique         2                                              49582\n",
              "top          neg  Loved today's show!!! It was a variety and not...\n",
              "freq       25000                                                  5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYpicMxDymtU",
        "outputId": "09d0f067-54bf-4027-dc98-0683b7113c98"
      },
      "source": [
        "df_imdb_raw.nunique()"
      ],
      "id": "DYpicMxDymtU",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment        2\n",
              "review       49582\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w6KHilEKyq6M",
        "outputId": "81754b88-e306-458e-d0a4-65cace44cbe6"
      },
      "source": [
        "df_imdb_raw.head()"
      ],
      "id": "w6KHilEKyq6M",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>If only to avoid making this type of film in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>This film was probably inspired by Godard's Ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                             review\n",
              "0       neg  I rented I AM CURIOUS-YELLOW from my video sto...\n",
              "1       neg  \"I Am Curious: Yellow\" is a risible and preten...\n",
              "2       neg  If only to avoid making this type of film in t...\n",
              "3       neg  This film was probably inspired by Godard's Ma...\n",
              "4       neg  Oh, brother...after hearing about this ridicul..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "G8SQAEXWytB1",
        "outputId": "09d8b68f-2271-42d3-9583-114787a64c7f"
      },
      "source": [
        "df_imdb_raw.tail()"
      ],
      "id": "G8SQAEXWytB1",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>pos</td>\n",
              "      <td>Just got around to seeing Monster Man yesterda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>pos</td>\n",
              "      <td>I got this as part of a competition prize. I w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>pos</td>\n",
              "      <td>I got Monster Man in a box set of three films ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>pos</td>\n",
              "      <td>Five minutes in, i started to feel how naff th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>pos</td>\n",
              "      <td>I caught this movie on the Sci-Fi channel rece...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentiment                                             review\n",
              "49995       pos  Just got around to seeing Monster Man yesterda...\n",
              "49996       pos  I got this as part of a competition prize. I w...\n",
              "49997       pos  I got Monster Man in a box set of three films ...\n",
              "49998       pos  Five minutes in, i started to feel how naff th...\n",
              "49999       pos  I caught this movie on the Sci-Fi channel rece..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yG0JRUj3yw26",
        "outputId": "3ff62c7b-5831-4317-8742-37a1119b498e"
      },
      "source": [
        "df_imdb_raw[df_imdb_raw.duplicated()]"
      ],
      "id": "yG0JRUj3yw26",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>neg</td>\n",
              "      <td>I am not so much like Love Sick as I image. Fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>neg</td>\n",
              "      <td>Holy freaking God all-freaking-mighty. This mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>neg</td>\n",
              "      <td>The story and the show were good, but it was r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3070</th>\n",
              "      <td>neg</td>\n",
              "      <td>I watched this movie when Joe Bob Briggs hoste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3591</th>\n",
              "      <td>neg</td>\n",
              "      <td>I like Chris Rock, but I feel he is wasted in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49911</th>\n",
              "      <td>pos</td>\n",
              "      <td>I watched Pola X because Scott Walker composed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49912</th>\n",
              "      <td>pos</td>\n",
              "      <td>Leos Carax has made 3 great movies: Boys Meet ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49913</th>\n",
              "      <td>pos</td>\n",
              "      <td>Leos Carax is brilliant and is one of the best...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49914</th>\n",
              "      <td>pos</td>\n",
              "      <td>I've tried to reconcile why so many bad review...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49962</th>\n",
              "      <td>pos</td>\n",
              "      <td>I have seen most of the Tarzan episodes. Certa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentiment                                             review\n",
              "168         neg  I am not so much like Love Sick as I image. Fi...\n",
              "664         neg  Holy freaking God all-freaking-mighty. This mo...\n",
              "701         neg  The story and the show were good, but it was r...\n",
              "3070        neg  I watched this movie when Joe Bob Briggs hoste...\n",
              "3591        neg  I like Chris Rock, but I feel he is wasted in ...\n",
              "...         ...                                                ...\n",
              "49911       pos  I watched Pola X because Scott Walker composed...\n",
              "49912       pos  Leos Carax has made 3 great movies: Boys Meet ...\n",
              "49913       pos  Leos Carax is brilliant and is one of the best...\n",
              "49914       pos  I've tried to reconcile why so many bad review...\n",
              "49962       pos  I have seen most of the Tarzan episodes. Certa...\n",
              "\n",
              "[418 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wReGv2MP4jM2"
      },
      "source": [
        "Necessário remover stopwords, caracteres que não são alfabeto e transformar para lowercase.\n",
        "\n",
        "Há também casos duplicados."
      ],
      "id": "wReGv2MP4jM2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5feMB-U3NSF"
      },
      "source": [
        "Pré processamento"
      ],
      "id": "k5feMB-U3NSF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou1VWI3kzOnz"
      },
      "source": [
        "df_cleaned = df_imdb_raw.drop_duplicates()"
      ],
      "id": "ou1VWI3kzOnz",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "6Qiax8U6cwJi",
        "outputId": "c1389f21-e85d-49cf-c51e-cd2677315e6f"
      },
      "source": [
        "df_cleaned.describe()"
      ],
      "id": "6Qiax8U6cwJi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>49582</td>\n",
              "      <td>49582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>49582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>pos</td>\n",
              "      <td>1981's Just Before Dawn is one of the best tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>24884</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentiment                                             review\n",
              "count      49582                                              49582\n",
              "unique         2                                              49582\n",
              "top          pos  1981's Just Before Dawn is one of the best tal...\n",
              "freq       24884                                                  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxURGahE2xrA",
        "outputId": "3b040c14-3e7c-43e7-bfbd-5cc19c16d9ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "english_stops = set(stopwords.words('english'))"
      ],
      "id": "cxURGahE2xrA",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V5C3ure3dVn",
        "outputId": "ecfb94f5-02c5-412e-d0ba-a85935ac3e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_cleaned['review'] = df_cleaned['review'].replace({'<.*?>': ''}, regex = True)\n",
        "df_cleaned['review'] = df_cleaned['review'].replace({'[^A-Za-z]': ' '}, regex = True)\n",
        "df_cleaned['review'] = df_cleaned['review'].apply(lambda review: [w for w in review.split() if w not in english_stops])\n",
        "df_cleaned['review'] = df_cleaned['review'].apply(lambda review: [w.lower() for w in review])"
      ],
      "id": "3V5C3ure3dVn",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4LveKbh4BZX",
        "outputId": "fc70969b-b4bf-499e-b609-3d7961137ef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_cleaned['sentiment'] = df_cleaned['sentiment'].replace('neg', 0)\n",
        "df_cleaned['sentiment'] = df_cleaned['sentiment'].replace('pos', 1)"
      ],
      "id": "O4LveKbh4BZX",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wer_UgA4Mrq",
        "outputId": "f7851d3c-8858-42d9-b857-9d0bffeea8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df_cleaned.head()"
      ],
      "id": "7wer_UgA4Mrq",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[i, rented, i, am, curious, yellow, video, sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[i, am, curious, yellow, risible, pretentious,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[if, avoid, making, type, film, future, this, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[this, film, probably, inspired, godard, mascu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[oh, brother, hearing, ridiculous, film, umpte...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             review\n",
              "0          0  [i, rented, i, am, curious, yellow, video, sto...\n",
              "1          0  [i, am, curious, yellow, risible, pretentious,...\n",
              "2          0  [if, avoid, making, type, film, future, this, ...\n",
              "3          0  [this, film, probably, inspired, godard, mascu...\n",
              "4          0  [oh, brother, hearing, ridiculous, film, umpte..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLxM1UEkIVsV",
        "outputId": "520eabde-98ce-4a7e-83f6-b9f4760093b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df_cleaned.tail()"
      ],
      "id": "MLxM1UEkIVsV",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>1</td>\n",
              "      <td>[just, got, around, seeing, monster, man, yest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>1</td>\n",
              "      <td>[i, got, part, competition, prize, i, watched,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>1</td>\n",
              "      <td>[i, got, monster, man, box, set, three, films,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>1</td>\n",
              "      <td>[five, minutes, started, feel, naff, looking, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>1</td>\n",
              "      <td>[i, caught, movie, sci, fi, channel, recently,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentiment                                             review\n",
              "49995          1  [just, got, around, seeing, monster, man, yest...\n",
              "49996          1  [i, got, part, competition, prize, i, watched,...\n",
              "49997          1  [i, got, monster, man, box, set, three, films,...\n",
              "49998          1  [five, minutes, started, feel, naff, looking, ...\n",
              "49999          1  [i, caught, movie, sci, fi, channel, recently,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9KjQSiaB5ML"
      },
      "source": [
        "all_text = [item for sublist in [w for w in df_cleaned['review']] for item in sublist]"
      ],
      "id": "i9KjQSiaB5ML",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnLOCRlQCJ4K",
        "outputId": "45d231ba-774f-4eca-af95-db6c1c6ef3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(all_text)"
      ],
      "id": "GnLOCRlQCJ4K",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6436912"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybqY1AB0CPcj"
      },
      "source": [
        "chars = tuple(set(all_text))\n",
        "int2char = dict(enumerate(chars))\n",
        "char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "\n",
        "encoded = np.array([char2int[ch] for ch in all_text])"
      ],
      "id": "ybqY1AB0CPcj",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUaUsGzDXaGA"
      },
      "source": [
        "X = df_cleaned.drop('sentiment', axis=1)"
      ],
      "id": "mUaUsGzDXaGA",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5CcQXLUXjFM"
      },
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df_cleaned['sentiment'].values)"
      ],
      "id": "t5CcQXLUXjFM",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaE6VMpMXVFG"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "id": "xaE6VMpMXVFG",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wkL5usIYPYr"
      },
      "source": [
        "x_train = x_train['review']"
      ],
      "id": "1wkL5usIYPYr",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7--iYMIdthn"
      },
      "source": [
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)"
      ],
      "id": "R7--iYMIdthn",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66NxPG0Eesk7"
      },
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ],
      "id": "66NxPG0Eesk7",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ybKoP8eyEf",
        "outputId": "875eebe0-e106-46f7-d7d7-1aa7790ee3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "id": "Z2ybKoP8eyEf",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded X Train\n",
            " [[    1    13   422 ...     0     0     0]\n",
            " [    7     9    65 ...     0     0     0]\n",
            " [    8     4   143 ...     0     0     0]\n",
            " ...\n",
            " [    1   162     4 ...     0     0     0]\n",
            " [  144 13555   154 ...     0     0     0]\n",
            " [    2 11824   183 ...     0     0     0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[614   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]] \n",
            "\n",
            "Maximum review length:  130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvYIIKkSJ1fL"
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    \n",
        "    # Inicializa array\n",
        "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "    \n",
        "    # Preenche com valor 1\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    \n",
        "    # Reshape\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    \n",
        "    return one_hot"
      ],
      "id": "LvYIIKkSJ1fL",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2EZJQ5uJ2Wr"
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "    \n",
        "    batch_size_total = batch_size * seq_length\n",
        "    n_batches = len(arr)//batch_size_total\n",
        "    \n",
        "    arr = arr[:n_batches * batch_size_total]\n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    \n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "id": "i2EZJQ5uJ2Wr",
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgA7wAB5f1ol"
      },
      "source": [
        "Define a arquitetura"
      ],
      "id": "QgA7wAB5f1ol"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP3nqVz-_ut_",
        "outputId": "ce488089-4dff-4c41-ca99-d7e74b2f2943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "english_stops = set(stopwords.words('english'))"
      ],
      "id": "cP3nqVz-_ut_",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si1eAnrHjT9R"
      },
      "source": [
        "class ImdbDataset(Dataset):\n",
        "    \"\"\"Imdb Dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, df_raw):\n",
        "      df_cleaned = df_raw\n",
        "\n",
        "      df_cleaned['review'] = df_cleaned['review'].replace({'<.*?>': ''}, regex = True)\n",
        "      df_cleaned['review'] = df_cleaned['review'].replace({'[^A-Za-z]': ' '}, regex = True)\n",
        "      df_cleaned['review'] = df_cleaned['review'].apply(lambda review: [w for w in review if w not in english_stops])\n",
        "      df_cleaned['review'] = df_cleaned['review'].apply(lambda review: [w.lower() for w in review])\n",
        "\n",
        "      #df_cleaned['review_chars'] = df_cleaned['review'].apply(lambda x: tuple(set(x)))\n",
        "      #df_cleaned['review_int2char'] = df_cleaned['review_chars'].apply(lambda x: dict(enumerate(x)))\n",
        "      #df_cleaned['review_char2int'] = df_cleaned['review_int2char'].apply(lambda x: {ch: ii for ii, ch in x.items()})\n",
        "      #df_cleaned['review_encoded'] = df_cleaned['review'].apply(self.encode_review)\n",
        "\n",
        "      self.all_text = [item for sublist in [w for w in df_cleaned['review']] for item in sublist]\n",
        "      self.chars = tuple(set(self.all_text))\n",
        "      self.int2char = dict(enumerate(self.chars))\n",
        "      self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "\n",
        "      self.encoded = np.array([self.char2int[ch] for ch in self.all_text])\n",
        "\n",
        "      self.imdb_frame = df_cleaned\n",
        "\n",
        "      # Save target and predictors\n",
        "      self.X = self.imdb_frame.drop('sentiment', axis=1)\n",
        "\n",
        "      le = LabelEncoder()\n",
        "      self.y = le.fit_transform(self.imdb_frame['sentiment'].values)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.imdb_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "\n",
        "      features = self.X.iloc[idx].values\n",
        "      print(features)\n",
        "      target = self.y[idx].astype(str).astype(int)\n",
        "      print(target)\n",
        "\n",
        "      sample = [features, target]\n",
        "\n",
        "      return sample\n",
        "\n",
        "    def encode_review(self, x: str):\n",
        "      chars = tuple(set(x))\n",
        "      int2char = dict(enumerate(chars))\n",
        "      char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "      return np.array([char2int[ch] for ch in x])"
      ],
      "id": "si1eAnrHjT9R",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52GsGncspaLu"
      },
      "source": [
        "imdb_dataset = ImdbDataset(df_imdb_raw)"
      ],
      "id": "52GsGncspaLu",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oO6FwmjLFcP"
      },
      "source": [
        "# Split into training and test\n",
        "train_size = int(0.7 * len(imdb_dataset))\n",
        "test_size = len(imdb_dataset) - train_size\n",
        "trainset, testset = random_split(imdb_dataset, [train_size, test_size])"
      ],
      "id": "5oO6FwmjLFcP",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB0iIz4FLQDS"
      },
      "source": [
        "# Dataloaders\n",
        "train_dataloader = DataLoader(trainset, batch_size=200, shuffle=True)\n",
        "test_dataloader = DataLoader(testset, batch_size=200, shuffle=False)"
      ],
      "id": "NB0iIz4FLQDS",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUkEXQhof2cZ"
      },
      "source": [
        "class ImdbLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
        "                               drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        \n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "        \n",
        "        #definir lstm input_size, hidden_size, num_layers\n",
        "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        #definir dropout\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "        #definir camada fc num_hidden input_size\n",
        "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "                \n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        out = self.dropout(r_output)\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # Gera tensores de tamanho n_layers x betch_size x n_hidden\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "id": "tUkEXQhof2cZ",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCHVOvuPfzcm"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "id": "NCHVOvuPfzcm",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fulRZjuGgERL"
      },
      "source": [
        "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "    net.train()\n",
        "    \n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    #dados de treino/validacao\n",
        "    val_idx = int(len(data)*(1-val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "            # One-hot encoding\n",
        "            x = one_hot_encode(x, n_chars)\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            \n",
        "            # Cria variáveis para hidden state \n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # saida do modelo\n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "            loss.backward()\n",
        "            \n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            opt.step()\n",
        "            \n",
        "            if counter % print_every == 0:\n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                    \n",
        "                    x = one_hot_encode(x, n_chars)\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "\n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "                \n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                net.train() \n",
        "                \n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "id": "fulRZjuGgERL",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swt8MXB0gLc7"
      },
      "source": [
        "Treinamento"
      ],
      "id": "Swt8MXB0gLc7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyAn4G7JgNY5",
        "outputId": "b4b4613c-74a6-4dd1-dc0b-8d4f26beb95e"
      },
      "source": [
        "n_hidden=256\n",
        "n_layers=2\n",
        "\n",
        "net = ImdbLSTM(chars, n_hidden, n_layers)\n",
        "print(net)"
      ],
      "id": "VyAn4G7JgNY5",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ImdbLSTM(\n",
            "  (lstm): LSTM(101397, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=101397, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vZTmi_gTip"
      },
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 110\n",
        "\n",
        "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)"
      ],
      "id": "w9vZTmi_gTip",
      "execution_count": null,
      "outputs": []
    }
  ]
}